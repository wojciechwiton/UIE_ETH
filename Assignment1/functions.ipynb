{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def chunks(arr, n_arr):\n",
    "    \n",
    "    n_elems = int(math.ceil(len(arr)/n_arr))\n",
    "    return [arr[i:i + n_elems] for i in range(0, len(arr), n_elems)]\n",
    "\n",
    "print('\\tchunks() loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def part_histograms(img, x_parts=4, y_parts=3, bins=1):\n",
    "    \n",
    "    (x_dim, y_dim) = img.shape\n",
    "    x_pix, y_pix = chunks(range(x_dim),x_parts), chunks(range(y_dim),y_parts)\n",
    "    \n",
    "    part_array = np.array([])\n",
    "    \n",
    "    for j in range(len(x_pix)):\n",
    "        x_range = x_pix[j]\n",
    "\n",
    "        for k in range(len(y_pix)):\n",
    "            y_range = y_pix[k]\n",
    "\n",
    "            indeces = np.ix_(x_range, y_range)\n",
    "            img_part = img[indeces]\n",
    "            if bins == 1:\n",
    "                hist = img_part.sum()\n",
    "            else:\n",
    "                hist, bin_edges = np.histogram(img_part.ravel(), range=(1e-5,np.max(img.ravel())), bins=bins)\n",
    "\n",
    "            part_array = np.hstack((part_array, hist))\n",
    "        \n",
    "    return part_array\n",
    "\n",
    "print('\\tpart_histograms() loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cropImage(img, img_segmentation, crop=True):\n",
    "    \n",
    "    if crop == True:\n",
    "        mask = np.mean(img_segmentation, axis=2) > 150 # For depth images\n",
    "        if img.ndim == 3:\n",
    "            mask = np.dstack((mask,mask,mask))\n",
    "\n",
    "        x_zero = np.where(np.all(mask==0, axis=1) == 1)\n",
    "        y_zero = np.where(np.all(mask==0, axis=0) == 1)\n",
    "\n",
    "        img = np.delete(img, x_zero, axis=0)\n",
    "        img = np.delete(img, y_zero, axis=1)\n",
    "\n",
    "        mask = np.delete(mask, x_zero, axis=0)\n",
    "        mask = np.delete(mask, y_zero, axis=1)\n",
    "    else:\n",
    "        mask = np.mean(img_segmentation, axis=2) > 150 # For depth images\n",
    "        \n",
    "    return img, mask\n",
    "\n",
    "print(\"\\tcropImage() loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rescaleDepthImage(img, img_segmentation, std=3):\n",
    "    \n",
    "    _, mask = cropImage(img, img_segmentation, False)\n",
    "    ma = img[np.nonzero(img*mask)]\n",
    "    img_min = max(np.mean(ma) - std * np.std(ma), np.min(ma))\n",
    "    img_max = min(np.mean(ma) + std * np.std(ma), np.max(ma))\n",
    "    \n",
    "    img = (img - img_min)/(img_max - img_min)*255*mask\n",
    "    img = cv2.convertScaleAbs(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "print('\\trescaleDepthImage loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, labels_train, method='rf', use_pca=False):\n",
    "    \n",
    "    if use_pca == True:\n",
    "        param_svm ={\n",
    "        \"pca__n_components\": [20, 40, 60],\n",
    "        \"svm__kernel\": ['rbf'],\n",
    "        \"svm__gamma\": [1e-3, 1e-4],\n",
    "        \"svm__C\": [0.01, 1, 10, 100]}\n",
    "        pipe_svm = Pipeline([('pca', PCA()), ('svm', SVC())])\n",
    "        clf_svm = GridSearchCV(pipe_svm, param_svm, cv=5, n_jobs=8)\n",
    "    else:\n",
    "        param_svm ={\n",
    "        \"kernel\": ['rbf'],\n",
    "        \"gamma\": [1e-3, 1e-4],\n",
    "        \"C\": [0.01, 1, 10, 100]}\n",
    "        clf_svm = GridSearchCV(SVC(), param_svm, cv=5, n_jobs=4)\n",
    "    \n",
    "    param_rf = {\n",
    "        \"max_depth\": [None],\n",
    "        \"max_features\": [20, 40],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 3, 10],\n",
    "        \"n_estimators\": [6, 10, 20],\n",
    "        \"bootstrap\": [True, False],\n",
    "        \"criterion\": [\"entropy\", \"gini\"]}\n",
    "    clf_rf = GridSearchCV(RandomForestClassifier(n_jobs=4), param_rf, cv=5, n_jobs=4)\n",
    "    \n",
    "    if use_pca == True:\n",
    "        param_lr = {\n",
    "            \"pca__n_components\": [20, 40, 60],\n",
    "            \"logistic__C\" : np.logspace(-4, 4, 3)}\n",
    "        pipe_lr = Pipeline([('pca', PCA()), ('logistic', LogisticRegression(n_jobs=4))])\n",
    "        clf_lr = GridSearchCV(pipe_lr, param_lr, cv=5, n_jobs=4)\n",
    "    else:\n",
    "        param_lr = {\n",
    "            \"C\" : np.logspace(-4, 4, 3)}\n",
    "        clf_lr = GridSearchCV(LogisticRegression(n_jobs=4), param_lr, cv=5, n_jobs=4)\n",
    "    \n",
    "    if method == 'svm':\n",
    "        clf = clf_svm\n",
    "    elif method == 'rf':\n",
    "        clf = clf_rf\n",
    "    elif method == 'lr':\n",
    "        clf = clf_lr\n",
    "    elif method == 'voting':\n",
    "        clf = VotingClassifier([('lr', clf_lr), ('rf', clf_rf), ('svm', clf_svm)], voting='hard')\n",
    "    \n",
    "    clf.fit(X_train, labels_train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "print('\\ttrain() loaded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
