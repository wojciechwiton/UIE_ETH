{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import datetime, os\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading global functions from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb\n",
    "\n",
    "print('importing functions done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataTrain = pickle.load(open(\"a1_dataTrain.pkl\", 'rb'))\n",
    "dataTest = pickle.load(open(\"a1_dataTest.pkl\", 'rb'))\n",
    "\n",
    "print('data loading done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for false segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_count = len(dataTrain['rgb'])\n",
    "test_count = len(dataTest['rgb'])\n",
    "good_train_indices = [i for i in range(0, train_count) if dataTrain['segmentation'][i].sum() != 0]\n",
    "good_test_indices = [i for i in range(0, test_count) if dataTest['segmentation'][i].sum() != 0]\n",
    "\n",
    "print('found data with good segmentation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating features - local histograms on depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run functions.ipynb\n",
    "\n",
    "train_count = len(dataTrain['rgb'])\n",
    "test_count = len(dataTest['rgb'])\n",
    "\n",
    "# Number of parts in which to divide each depth image\n",
    "x_parts = 8\n",
    "y_parts = 6\n",
    "bins = 5\n",
    "std = 3\n",
    "# Plus 1 because of adding subject label\n",
    "n_features = x_parts * y_parts * bins + 1\n",
    "\n",
    "X_train = np.zeros((train_count, n_features))\n",
    "X_test = np.zeros((test_count, n_features))\n",
    "\n",
    "for i in good_train_indices:\n",
    "    img_depth = dataTrain['depth'][i]\n",
    "    img_segmentation = dataTrain['segmentation'][i]\n",
    "    subject_train = dataTrain['subjectLabels'][i]\n",
    "    \n",
    "    img_depth = rescaleDepthImage(img_depth, img_segmentation, std)\n",
    "    img_depth, mask = cropImage(img_depth, img_segmentation)\n",
    "    img_depth = imresize(img_depth*mask,(120,90))\n",
    "    img_depth[90:,:] = 0\n",
    "    img_depth[75:, 30:60] = 0\n",
    "    \n",
    "    X_train[i,:n_features-1] = part_histograms(img_depth, x_parts, y_parts, bins)\n",
    "    X_train[i,n_features-1] = subject_train\n",
    "    \n",
    "    if i%1000 == 0: print(i)\n",
    "    \n",
    "for i in good_test_indices:\n",
    "    img_depth = dataTest['depth'][i]\n",
    "    img_segmentation = dataTest['segmentation'][i]\n",
    "    subject_test = dataTest['subjectLabels'][i]\n",
    "\n",
    "    img_depth = rescaleDepthImage(img_depth, img_segmentation, std)\n",
    "    img_depth, mask = cropImage(img_depth, img_segmentation)\n",
    "    img_depth = imresize(img_depth*mask,(120,90))\n",
    "    img_depth[90:,:] = 0\n",
    "    img_depth[75:, 30:60] = 0\n",
    "    \n",
    "    X_test[i,:n_features-1] = part_histograms(img_depth, x_parts, y_parts, bins)\n",
    "    X_test[i,n_features-1] = subject_test\n",
    "    \n",
    "    if i%1000 == 0: print(i)\n",
    "        \n",
    "print('features generation done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving features to pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open( \"train_features_histograms.p\", \"wb\" ) )\n",
    "pickle.dump(X_test, open( \"test_features_histograms.p\", \"wb\" ) )\n",
    "\n",
    "print('saving features done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training classifier - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels_train = dataTrain['gestureLabels'][:]\n",
    "\n",
    "clf = train(X_train, labels_train, 'rf')\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "\n",
    "print('training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels_test = clf.predict(X_test)\n",
    "\n",
    "print('prediction done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "date_format = \"%d%m%y_%H%M%S\"\n",
    "date = today.strftime(date_format)\n",
    "\n",
    "savepath = os.path.join(\"results\", \"output_\" + date + \".txt\")\n",
    "with open(savepath, \"w\") as text_file:\n",
    "    text_file.write(\"Date: \" + str(today) + \"\\n\")\n",
    "    text_file.write(\"Parts: \" + str(x_parts) + \" \" + str(y_parts) + \"\\n\")\n",
    "    text_file.write(\"Std: \" + str(std) + \"\\n\")\n",
    "    text_file.write(\"Best estimator: \" + str(clf.best_estimator_) + \"\\n\")\n",
    "    text_file.write(\"Best params: \" + str(clf.best_params_) + \"\\n\")\n",
    "    text_file.write(\"Score: \" + str(clf.best_score_) + \"\\n\")\n",
    "\n",
    "labels_test = labels_test.ravel()\n",
    "\n",
    "nr = np.arange(1,test_count+1)\n",
    "\n",
    "savepath = os.path.join(\"results\", \"submission_\" + date + \".csv\")\n",
    "data = {\"Id\" : nr, \"Prediction\" : labels_test}\n",
    "df = pd.DataFrame(data, columns=['Id', 'Prediction'])\n",
    "df.to_csv(savepath, index=False)\n",
    "\n",
    "print('results saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
